# library
```{r setup}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	include = FALSE
)

# For code reproducibility: and git
library(here) # project-based relative path finding 
library(usethis) # git set-up

# For data manipulation
library(tidyverse)
library(data.table, include.only = "fread")

# For specific parts of the code
library(Hmisc, include.only = "hist.data.frame") # For quick visualisation of distribution
library(qqman) # For Manhattan plot
```

# Image Data preprocessing
## white matter tract: FINALISED
```{r White matter tract phenotype data standardisation and outlier removal, eval=FALSE, include=FALSE}
# STEP1: Find file paths and names
tract_path = list.files("/rds/user/yg330/rds-genetics_hpc-Nl99R8pHODQ/UKB/Imaging_genetics/yg330/raw data/tracts", full.names = TRUE)
tract_name = gsub("/rds/user/yg330/rds-genetics_hpc-Nl99R8pHODQ/UKB/Imaging_genetics/yg330/raw data/tracts/|dti_|NODDI_|.csv", "", tract_path) # remove anything fit the patterns
tract_name = paste0("tract_", tract_name) # add distinction for names
outlier_stat <- data.frame(tract = character(), region = character(), outlier_Count = integer(), outlier_Rows = character())

# STEP 2: Remove outliers with values beyond 5 standard deviation (SD) and 5 median absolute deviation (MAD)
for (i in seq_along(tract_path)) {
  # Read and process tract data
  tmp_tract <- read.csv(tract_path[i])
  tmp_tract_name <- tract_name[i]
  
  # format for GWAS
  tmp_tract$Subject = as.numeric(gsub("UKB", "", tmp_tract$Subject))
  tmp_tract = tmp_tract %>% rename(FID = Subject) %>% mutate(IID = FID) %>% relocate(FID, IID) # rename Subject to FID -> duplicate FID as IID -> move to correct order.
  
  # Z-score standardisation on numerical columns
  tmp_tract[, 3:ncol(tmp_tract)] <- scale(tmp_tract[, 3:ncol(tmp_tract)])
  
  # Remove z-score outliers (beyond Â±5 SD)
  tmp_tract <- tmp_tract %>% mutate(across(3:ncol(.), ~ ifelse(. > 5 | . < -5, NA, .)))
  
  # save standardised tract table
  assign(tmp_tract_name, tmp_tract)
  
  # Process Median Absolute Deviation (MAD) outliers
  for (j in 3:ncol(tmp_tract)) {
    # find MAD
    col_name <- colnames(tmp_tract)[j]
    col_mad <- mad(tmp_tract[[col_name]], na.rm = TRUE)
    
    # Find MAD outlier number and location
    mad_outlier <- abs(tmp_tract[[col_name]]) > col_mad * 5
    col_mad_outlier_n <- sum(mad_outlier, na.rm = TRUE)
    outlier_rows <- which(mad_outlier)
    
    if (col_mad_outlier_n > 0) {
      print(sprintf(
        "In %s: %d MAD outliers detected in %s", 
        tmp_tract_name, 
        col_mad_outlier_n, 
        col_name
      ))
      # remove MAD outliers
      tmp_tract[[col_name]][mad_outlier] <- NA
      
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          tract = tmp_tract_name,
          region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    } else {
      print(sprintf(
        "In %s: No MAD outliers in %s", 
        tmp_tract_name, 
        col_name
      ))
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          tract = tmp_tract_name,
          region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    }
  }
  
  # Assign processed tract data
  tract_name_mad <- paste0(tract_name[i], ".mad")
  assign(tract_name_mad, tmp_tract)
}



# STEP3: Generate results
write.table(outlier_stat, file = paste0(here("result_supplement/mad_hist_stat/"), "white_matter_tract.mad_outliers.txt"), row.names = FALSE, col.names = TRUE, quote = FALSE) # white matter tract outlier stat

for (i in seq_along(tract_name)){
  # set results path
  sd.result_path = paste0(here("result_supplement/imaging_data_final/"), tract_name[i], ".sd.QCed.txt")
  sd.mad.result_path = paste0(here("result_supplement/imaging_data_final/"), tract_name[i], ".sd.mad.QCed.txt")
  sd.hist_path = paste0(here("result_supplement/mad_hist_stat/"), tract_name[i], ".sd.pdf")
  sd.mad.hist_path = paste0(here("result_supplement/mad_hist_stat/"), tract_name[i], ".sd.mad.pdf")
  
  # get and write respective table
  sd.result = get(tract_name[i])
  sd.mad.result = get(paste0(tract_name[i], ".mad"))
  
  write.table(sd.result, file = sd.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  write.table(sd.mad.result, file = sd.mad.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  
  # generate respective histogram
  pdf(file = sd.hist_path)
    hist(sd.result)
  dev.off()
  
  pdf(file = sd.mad.hist_path)
    hist(sd.mad.result)
  dev.off()
}

```

## subcortical volume: FINALISED
```{r Subcortical volume phenotype data standardisation and outlier removal, eval=FALSE, include=FALSE}
# STEP1: Select subcortical regions from Amir's dataset

# These data have already gone through standardisation and mean+-5SD outlier removal.
# For details of how the data is generated and cleaned, please check Amir's Jupyter notebook file named "Cleaning.ipynb" in the imaging data folder.

raw_data_sub = read.csv(here("imaging_data/All_IDP_subcortical_Amir.csv"))

raw_data_sub_selected = raw_data_sub %>% select("IID", "Lateral.Ventricle", "Inf.Lat.Vent", "Cerebellum.White.Matter", "Cerebellum.Cortex", "Thalamus.Proper", "Caudate", "Putamen", "Pallidum", "Hippocampus", "Amygdala", "Accumbens.area", "VentralDC", "vessel", "choroid.plexus", "X3rd.Ventricle", "X4th.Ventricle", "Brain.Stem", "CSF", "WM.hypointensities", "Optic.Chiasm", "CC_Posterior", "CC_Mid_Posterior", "CC_Central", "CC_Mid_Anterior", "CC_Anterior", "SubCortGrayVol")
raw_data_sub_selected$FID = raw_data_sub_selected$IID

write.table(raw_data_sub_selected, file = here("imaging_data/All_IDP_Amir_subcortical.only.txt"), row.names = F, col.names = T, quote = F)

# format to GWAS-ready format
subcor = fread(here("imaging_data/All_IDP_Amir_subcortical.only.txt"))
subcor.formatted = subcor %>% relocate("FID", "IID")
write.table(subcor.formatted, file = here("imaging_data/subcortical_formatted.txt"), row.names = F, col.names = T, quote = F)


# STEP2: Process Median Absolute Deviation (MAD) outliers
subcor.formatted = fread(here("imaging_data/subcortical_formatted.txt"))
subcor.formatted.mad = subcor.formatted
outlier_stat <- data.frame(subcor_region = character(), outlier_Count = integer(), outlier_Rows = character())

  for (j in 3:ncol(subcor.formatted.mad)) {
    # find MAD
    col_name <- colnames(subcor.formatted.mad)[j]
    col_mad <- mad(subcor.formatted.mad[[col_name]], na.rm = TRUE)
    
    # Find MAD outlier number and location
    mad_outlier <- abs(subcor.formatted.mad[[col_name]]) > col_mad * 5
    col_mad_outlier_n <- sum(mad_outlier, na.rm = TRUE)
    outlier_rows <- which(mad_outlier)
    
    if (col_mad_outlier_n > 0) {
      print(sprintf(
        "%d MAD outliers detected in %s",
        col_mad_outlier_n, 
        col_name
      ))
      # remove MAD outliers
      subcor.formatted.mad[[col_name]][mad_outlier] <- NA
      
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          subcor_region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    } else {
      print(sprintf(
        "No MAD outliers in %s", 
        col_name
      ))
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          subcor_region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    }
  }


# STEP3: Generate results
write.table(outlier_stat, file = paste0(here("result_supplement/mad_hist_stat/"), "subcor_volume.mad_outliers.txt"), row.names = FALSE, col.names = TRUE, quote = FALSE) # white matter tract outlier stat


# set results path
  sd.result_path = paste0(here("result_supplement/imaging_data_final/subcor_vol.sd.QCed.txt"))
  sd.mad.result_path = paste0(here("result_supplement/imaging_data_final/subcor_vol.sd.mad.QCed.txt"))
  sd.hist_path = paste0(here("result_supplement/mad_hist_stat/subcor_vol.sd.pdf"))
  sd.mad.hist_path = paste0(here("result_supplement/mad_hist_stat/subcor_vol.sd.mad.pdf"))
  
# get and write respective table
  write.table(subcor.formatted, file = sd.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  write.table(subcor.formatted.mad, file = sd.mad.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  
# generate respective histogram
for (i in 1){
  pdf(file = sd.hist_path)
    hist(subcor.formatted)
  dev.off()
  
  pdf(file = sd.mad.hist_path)
    hist(subcor.formatted.mad)
  dev.off()
}

```
## Regional MRI phenotypes: FINALISED
```{r Regional Phenotype z-score standardisation and outlier Removal, eval=FALSE, include=FALSE}
# Read Regional MRI phenotype data
file.loc = list.files(here("imaging_data"), pattern="HCP.*\\.csv", full.names=TRUE)
file.name = gsub(here("imaging_data/HCP.fsaverage.aparc_|dti_|NODDI_|.csv"), "", file.loc) # remove anything fit the patterns

for (i in 1:length(file.loc)) { # for loop to read in all MRI phenotypes
  tmp_file = fread(file.loc[i])
  assign(file.name[i], tmp_file)
}

# List region names that will need to generate average regional values
region.names = grep("ROI", colnames(tmp_file), value = TRUE)
region.names = unique(gsub("lh_L_|rh_R_|_ROI", "", region.names))

# For loop for generating averaged region scores and z-score standardisation and outlier removal
for (i in 1:length(file.name)){
  tmp_file = get(file.name[i])
  tmp_file = tmp_file %>% select(-contains("???")) # remove medial wall columns if it exists.

  # Calculate average regional result and standardise it
  for (k in 1:length(region.names)){
    # Set names
    tmp_region_name = region.names[k]
    tmp_column_name = paste0("_", tmp_region_name, "_ROI")
    
    tmp_region_table = tmp_file %>% select("Subject", contains(tmp_column_name)) # to prevent accidentally selecting partially fit columns
    
    # Calculate average
    tmp_column_name_avg = paste0(tmp_region_name, "_avg")
    tmp_region_table[ , tmp_column_name_avg] = rowMeans(select(tmp_region_table, contains(tmp_column_name)))
    
    # z-score standardisation
    tmp_column_name_scl = paste0(tmp_region_name, "_avg_scaled")
    tmp_region_table[ , tmp_column_name_scl] = scale(select(tmp_region_table, contains("_avg")))
    
    tmp_file = full_join(tmp_file, tmp_region_table) # use warning message to make sure avg phenotypes are generated by correct columns
  }
  
  # Remove +-5SD outliers
  tmp_file_QC = select(tmp_file, Subject, contains("avg_scaled"))
  tmp_file_QC = tmp_file_QC %>% mutate(across(c(2:181), ~ ifelse(. > 5 | . < -5, NA, .)))
  
  # write results
  tmp_file_QC.loc = paste0("imaging_data/regional_", file.name[i], ".avg_scaled_QCed.txt")
  write.csv(tmp_file_QC, file = here(tmp_file_QC.loc), row.names = FALSE)
}
```
```{r Regional Phenotype median-outlier removal through MAD, eval=FALSE, include=FALSE}
# STEP1: Find file paths and names
file.loc = list.files(here("imaging_data"), pattern="avg_scaled_QCed.txt", full.names=TRUE)
file.name = gsub(here("imaging_data/|.avg_scaled_QCed.txt"), "", file.loc) # remove anything fit the patterns
outlier_stat <- data.frame(phenotype = character(), region = character(), outlier_Count = integer(), outlier_Rows = character())


# STEP 2: Remove outliers with values beyond 5 median absolute deviation (MAD)
for (i in seq_along(file.loc)) {
  # Read and process tract data
  tmp_ROI <- read.csv(file.loc[i])
  tmp_ROI_name <- file.name[i]
  
  # format for GWAS
  tmp_ROI$Subject = as.numeric(gsub("UKB", "", tmp_ROI$Subject))
  tmp_ROI = tmp_ROI %>% rename(FID = Subject) %>% mutate(IID = FID) %>% relocate(FID, IID) # rename Subject to FID -> duplicate FID as IID -> move to correct order.
  
  # Assign regional phenotype data
  assign(file.name[i], tmp_ROI)
  
  # Process Median Absolute Deviation (MAD) outliers
  for (j in 3:ncol(tmp_ROI)) {
    # find MAD
    col_name <- colnames(tmp_ROI)[j]
    col_mad <- mad(tmp_ROI[[col_name]], na.rm = TRUE)
    
    # Find MAD outlier number and location
    mad_outlier <- abs(tmp_ROI[[col_name]]) > col_mad * 5
    col_mad_outlier_n <- sum(mad_outlier, na.rm = TRUE)
    outlier_rows <- which(mad_outlier)
    
    if (col_mad_outlier_n > 0) {
      print(sprintf(
        "In %s: %d MAD outliers detected in %s", 
        tmp_ROI_name, 
        col_mad_outlier_n, 
        col_name
      ))
      # remove MAD outliers
      tmp_ROI[[col_name]][mad_outlier] <- NA
      
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          phenotype = tmp_ROI_name,
          region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    } else {
      print(sprintf(
        "In %s: No MAD outliers in %s", 
        tmp_ROI_name, 
        col_name
      ))
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          phenotype = tmp_ROI_name,
          region = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
    }
  }
  
  # Assign processed tract data
  file.name_mad <- paste0(file.name[i], ".mad")
  assign(file.name_mad, tmp_ROI)
}


# STEP3: Generate results
write.table(outlier_stat, file = paste0(here("result_supplement/mad_hist_stat/"), "regional_phenotypes.mad_outliers.txt"), row.names = FALSE, col.names = TRUE, quote = FALSE)

for (i in seq_along(file.name)){
  # set results path
  sd.result_path = paste0(here("result_supplement/imaging_data_final/"), file.name[i], ".sd.QCed.txt")
  sd.mad.result_path = paste0(here("result_supplement/imaging_data_final/"), file.name[i], ".sd.mad.QCed.txt")
  sd.hist_path = paste0(here("result_supplement/mad_hist_stat/"), file.name[i], ".sd.pdf")
  sd.mad.hist_path = paste0(here("result_supplement/mad_hist_stat/"), file.name[i], ".sd.mad.pdf")
  
  # get and write respective table
  sd.result = get(file.name[i])
  sd.mad.result = get(paste0(file.name[i], ".mad"))
  
  write.table(sd.result, file = sd.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  write.table(sd.mad.result, file = sd.mad.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
  
  # generate respective histogram
  pdf(file = sd.hist_path)
    hist(sd.result)
  dev.off()
  
  pdf(file = sd.mad.hist_path)
    hist(sd.mad.result)
  dev.off()
}
```
```{r Regional Phenotype Outlier stat further questions visualisation, fig.width=12, fig.height=6}
# Read-in table
outlier_stat <- read.csv2("/rds/user/yg330/hpc-work/pgs_img_2/result_supplement/mad_hist_stat/regional_phenotypes.mad_outliers.txt", sep="")

# Delete repeating prefix and suffix for easy readability in graphs
outlier_stat <- outlier_stat %>% 
  mutate(
    phenotype = str_remove(phenotype, "regional_"),
    region = str_remove(region, "_avg_scaled")
  )

# Question 1: Which phenotype have most non-zero outlier counts?
Q1 <-  outlier_stat %>% 
  filter(outlier_Count > 0) %>%  # select rows where outlier_Count is greater than 0
  ggplot(aes(x = phenotype)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Phenotype with regions with non-zero outlier count distribution", x = "Phenotype", y = "Count") 


# Question 2: What outlier n distribution is like?
Q2 <- ggplot(outlier_stat, aes(x = outlier_Count)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Outlier count distribution", x = "outliers count (0-1000)", y = "Count", caption = "There are 21 phenotype regions with > 1,000 outliers counts and 6 phenotype regions > 60,000") +
  xlim(0,1000)

# Question 3: Outlier distribution on different thresholds
Q3.100 <- outlier_stat %>% 
  filter(outlier_Count > 100) %>% 
  ggplot(aes(x = phenotype)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Phenotype Count with regions with > 100 outlier count Distribution", x = "Phenotype", y = "Count")

Q3.500 <- outlier_stat %>% 
  filter(outlier_Count > 500) %>% 
  ggplot(aes(x = phenotype)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Phenotype Count with regions with > 500 outlier count Distribution", x = "Phenotype", y = "Count")

Q3.1000 <- outlier_stat %>% 
  filter(outlier_Count > 1000) %>% 
  ggplot(aes(x = phenotype)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Phenotype Count with regions with > 1000 outlier count Distribution", x = "Phenotype", y = "Count")

# Question 4: Is there any regions that repeatedly have > 100 MAD outliers?
Q4.100.morethan3 <- outlier_stat %>%
  filter(outlier_Count > 100) %>% 
  count(region) %>%
  filter(n >= 4) %>%
  ggplot(aes(x = region, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Regions with repeated >100 outlier counts across more than 3 phenotypes", x = "Phenotype", y = "Count")

# (OPTIONAL) Question 5: Is any subject repeatedly appear as MAD outliers?

# Save in pdf

for (i in 1){ # to automatically click through pdf generation
  # generate respective histogram
  pdf(file = here("result_supplement/mad_hist_stat/regional_phenotypes.mad_questions.pdf"))
    print(Q1)
    print(Q2)
    print(Q3.100)
    print(Q3.500)
    print(Q3.1000)
    print(Q4.100.morethan3)
  dev.off()
}
```

## Global MRI phenotypes: FINALISED
```{r Create Global Phenotypes from Regional Phenotypes}
# Read Regional MRI phenotype data
file.loc = list.files(here("imaging_data"), pattern="HCP.*\\.csv", full.names=TRUE)
file.name = gsub(here("imaging_data/HCP.fsaverage.aparc_|dti_|NODDI_|.csv"), "", file.loc) # remove anything fit the patterns

for (i in 1:length(file.loc)) { # for loop to read in all MRI phenotypes
  tmp_file = fread(file.loc[i])
  assign(file.name[i], tmp_file)
}

# Global Phenotype Table
# left hemisphere and right hemisphere average
for (i in file.name){ # file.name
  tmp_file = get(i)
  # average by hemisphere and globally to create global phenotype
  tmp_file$lh_avg = rowMeans(select(tmp_file, contains("lh_"), -contains("???")))
  tmp_file$rh_avg = rowMeans(select(tmp_file, contains("rh_"), -contains("???")))
  tmp_file$global_avg = (tmp_file$lh_avg + tmp_file$rh_avg)/2
  
  # global phenotype standardisation
  tmp_file$lh_avg_scaled = scale(tmp_file$lh_avg)
  tmp_file$rh_avg_scaled = scale(tmp_file$rh_avg)
  tmp_file$global_avg_scaled = scale(tmp_file$global_avg)
  
  #rename for later merging
  colnames(tmp_file) = paste(colnames(tmp_file), i, sep=".")
  colnames(tmp_file)[1] <- "Subject"
  
  #assign to new data frame variable
  assign(paste0(i,".avg"), select(tmp_file, Subject, contains("avg")))
}

global.pheno = mget(paste0(file.name, ".avg")) %>% reduce(full_join, by = "Subject") # merge all data frames into one master table
write.csv(global.pheno, file=here("result_table/global.pheno.avg.scaled.txt"))
```
```{r Global Phenotype z-score standardisation and outlier removal, eval=FALSE, include=FALSE}
# Remove mean+-5SD outliers and only leave scaled global phenotype in
global.pheno.QCed = select(global.pheno, Subject, contains("scaled"))
global.pheno.QCed = global.pheno.QCed %>% mutate(across(c(2:37), ~ ifelse(. > 5 | . < -5, NA, .)))
write.csv(global.pheno.QCed, file=here("result_table/global.pheno.QCed.txt"))

# Format for GWAS
global.pheno.QCed = fread(here("result_table/global.pheno.QCed.txt"), drop = "V1") %>% select("Subject", contains("global")) # select only global phenotypes, remove hemisphere-based phenotypes
global.pheno.QCed$Subject = as.numeric(gsub("UKB", "", global.pheno.QCed$Subject))
global.pheno.QCed = global.pheno.QCed %>% rename(FID = Subject) %>% mutate(IID = FID) %>% relocate(FID, IID) # rename Subject to FID -> duplicate FID as IID -> move to correct order.

# Remove median outliers through MAD
global.pheno.QCed.mad = global.pheno.QCed # generate table to loop for
outlier_stat <- data.frame(phenotype = character(), outlier_Count = integer(), outlier_Rows = character())

for (j in 3:ncol(global.pheno.QCed.mad)){
  # find MAD
  col_name <- colnames(global.pheno.QCed.mad)[j]
  col_mad <- mad(global.pheno.QCed.mad[[col_name]], na.rm = TRUE)

  # Find MAD outlier number and location
  mad_outlier <- abs(global.pheno.QCed.mad[[col_name]]) > col_mad * 5
  col_mad_outlier_n <- sum(mad_outlier, na.rm = TRUE)
  outlier_rows <- which(mad_outlier)
  
  if (col_mad_outlier_n != 0) {
    print(sprintf(
        "%d MAD outliers detected in %s",
        col_mad_outlier_n, 
        col_name
      ))
      # remove MAD outliers
      global.pheno.QCed.mad[[col_name]][mad_outlier] <- NA
      
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          phenotype = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
  } else {
    print(sprintf(
        "No MAD outliers in %s", 
        col_name
      ))
      # Append to the outlier_stat for later visualisation
      outlier_stat <- rbind(
        outlier_stat,
        data.frame(
          phenotype = col_name,
          outlier_Count = col_mad_outlier_n,
          outlier_Rows = paste(outlier_rows, collapse = ",")
        )
      )
  }
}

# Generate results
write.table(outlier_stat, file = paste0(here("result_supplement/mad_hist_stat/"), "global_phenotypes.mad_outliers.txt"), row.names = FALSE, col.names = TRUE, quote = FALSE)


# set results path
sd.result_path = paste0(here("result_supplement/imaging_data_final/global_phenotypes.sd.QCed.txt"))
sd.mad.result_path = paste0(here("result_supplement/imaging_data_final/global_phenotypes.sd.mad.QCed.txt"))
sd.hist_path = paste0(here("result_supplement/mad_hist_stat/global_phenotypes.sd.pdf"))
sd.mad.hist_path = paste0(here("result_supplement/mad_hist_stat/global_phenotypes.sd.mad.pdf"))
  
# split table by DTI or STR MRI phenotypes for GWAS
DTI.global.pheno.QCed.mad = global.pheno.QCed.mad %>% select("FID", "IID", contains(c("FA", "MD", "OD", "ISOVF", "ICVF"))) # Diffusional phenotypes: FA,MD,OD,ISOVF,ICVF
STR.global.pheno.QCed.mad = global.pheno.QCed.mad %>% select("FID", "IID", contains(c("SA", "CT", "MC", "IC","FI", "GC", "GMV"))) %>% select(-contains("ICVF")) # Structural phenotypes: SA,CT,MC,IC,FI,GC,GMV
sd.mad.result_DTI_path = paste0(here("result_supplement/imaging_data_final/DTI_global_phenotypes.sd.mad.QCed.txt"))
sd.mad.result_STR_path = paste0(here("result_supplement/imaging_data_final/STR_global_phenotypes.sd.mad.QCed.txt"))
  
# get and write respective table
write.table(global.pheno.QCed, file = sd.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
write.table(global.pheno.QCed.mad, file = sd.mad.result_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
write.table(DTI.global.pheno.QCed.mad, file = sd.mad.result_DTI_path, row.names = FALSE, col.names = TRUE, quote = FALSE)
write.table(STR.global.pheno.QCed.mad, file = sd.mad.result_STR_path, row.names = FALSE, col.names = TRUE, quote = FALSE)

# generate respective histogram
for (i in 1){
  pdf(file = sd.hist_path)
    hist(global.pheno.QCed)
  dev.off()
  
  pdf(file = sd.mad.hist_path)
    hist(global.pheno.QCed.mad)
  dev.off()
}
```
# To be finalised: # Genetic Data preprocessing
```{r Find unique participant ID list}
# Find unique id number for participants with any MRI phenotype data
MRI.id.list = list(CT$Subject, FA$Subject, FI$Subject, GC$Subject, GMV$Subject, IC$Subject, ICVF$Subject, ISOVF$Subject, MC$Subject, MD$Subject, OD$Subject, SA$Subject)
keep.id = flatten(MRI.id.list)
keep.id = unique(keep.id)

keep.id = t(t(keep.id)) # change list to matrix, then a single row to a single column
colnames(keep.id) = "eid"
write.csv(keep.id, file = here("genetic_data/keep.id.UKB.txt"))

# Alternatively: If you want to find shared common ID that have data across all MRI phenotype
# keep.id = Reduce(intersect, list(CT$Subject, FA$Subject, FI$Subject, GC$Subject, GMV$Subject, IC$Subject, ICVF$Subject, ISOVF$Subject, MC$Subject, MD$Subject, OD$Subject, SA$Subject))

```

```{r Quality Control for Participant ID, eval=FALSE, include=FALSE}
# Participants QC
  # Select Self-identified white Europeans {keep 21000-0.0 %in% 1, 1001, 1002, 1003}
  # Remove Excessive heterozygosity {keep 22027-0.0 == NA}
  # Find Reported Sex and Genetic Sex Mismatch {keep 31-0.0 == 22001-0.0, ignore sex in NA if genetic sex is present} : Expected mistmatch number ~300 cases
  # Remove gPCA outliers using PCA1 and PCA2 to ensure genetically homozygous white European population {keep "22009-0.1" within its mean+-5SD and "22009-0.2" within its mean+-5SD}

# Pull relative fields from UKB latest data freeze
field_QC = c("eid", "21000-0.0", "31-0.0", "22001-0.0", "22027-0.0", "22009-0.1", "22009-0.2") 
QC = fread("/rds/user/yg330/rds-rb643-ukbiobank2/Data_Phenotype/DataFetch_20022024/ukb677594.csv",select = field_QC, header = T,sep=",")

QC_white = QC %>% filter(`21000-0.0` %in% c(1, 1001, 1002, 1003)) # Self-identified white Europeans
QC_white_low.hetero = filter(QC_white, is.na(QC_white$`22027-0.0`)) # Excessive heterozygousity (Expected 900 cases)


QC_white_low.hetero_with.mis.sex = filter(QC_white_low.hetero, QC_white_low.hetero$`31-0.0` != QC_white_low.hetero$`22001-0.0`) # find rows with mismatch (Expected ~300 cases)
QC_white_low.hetero_with.cor.sex = filter(QC_white_low.hetero, !QC_white_low.hetero$eid %in% QC_white_low.hetero_with.mis.sex$eid) # remove the rows with mismatch sex

# Remove gPCA outliers to ensure population is genetically homozygous
PC1_mean = mean(na.omit(QC_white_low.hetero_with.cor.sex$`22009-0.1`))
PC1_sd = sd(na.omit(QC_white_low.hetero_with.cor.sex$`22009-0.1`))
PC1_up.range = PC1_mean + 5*PC1_sd
PC1_low.range = PC1_mean - 5*PC1_sd

PC2_mean = mean(na.omit(QC_white_low.hetero_with.cor.sex$`22009-0.2`))
PC2_sd = sd(na.omit(QC_white_low.hetero_with.cor.sex$`22009-0.2`))
PC2_up.range = PC2_mean + 5*PC2_sd
PC2_low.range = PC2_mean - 5*PC2_sd

QC_white_low.hetero_with.cor.sex.homozygous = QC_white_low.hetero_with.cor.sex %>% filter(between(`22009-0.1`, PC1_low.range, PC1_up.range) & between(`22009-0.2`, PC2_low.range, PC2_up.range)) 
# Keep only rows within range in both PC1 and PC2

write.csv(QC_white_low.hetero_with.cor.sex.homozygous, file= here("result_table/UKB_ID.QCed.txt"), row.names = FALSE)

# Use UKB QCed population to filter out participants in the imaging
keep.id = fread(here("genetic_data/keep.id.UKB.txt"), drop = "V1", header = TRUE) # data read-in
keep.id =  gsub("UKB", "", keep.id$eid) # grab UKB ID

keep.id.QCed = filter(QC_white_low.hetero_with.cor.sex.homozygous, QC_white_low.hetero_with.cor.sex.homozygous$eid %in% keep.id) # select UKB ID where it is in the UKB QCed list
keep.id.QCed = select(keep.id.QCed, eid, `22001-0.0`) # select eid and sex
keep.id.QCed = rename(keep.id.QCed, "gSEX" = `22001-0.0`) # rename for better recognition
write.csv(keep.id.QCed, file = here("genetic_data/keep.id.UKB.QCed.txt"), row.names = FALSE)

# TODO: Check the following with Varun
# 14525	22003-0.0	487980	Continuous	Heterozygosity
# 14526	22004-0.0	487980	Continuous	Heterozygosity, PCA corrected
# 14527	22005-0.0	487980	Continuous	Missingness

# Use PCA corrected heterozygosity instead please
```